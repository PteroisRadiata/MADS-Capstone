{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "647bba6f",
   "metadata": {},
   "source": [
    "## Potential Pipeline Process\n",
    "\n",
    "Process that:\n",
    "\n",
    "1. fetches building footprints from OSM (OSMnx)\n",
    "\n",
    "2. reads your 15-minute demand tables from Supabase and computes annual energy need\n",
    "\n",
    "3. downloads GeoTIFFs from Supabase to compute a simple shade index per building\n",
    "\n",
    "4. estimates roof orientation, tilt, area, and per-building annual solar energy potential\n",
    "\n",
    "5. computes a composite solar_suitability score for each building\n",
    "\n",
    "6. selects a set of buildings (residential vs commercial) to meet the user’s chosen percentage of city power from solar while trying to respect the chosen commercial/building mix\n",
    "\n",
    "7. visualizes everything on a PyDeck map (colored polygons by solar_score and highlighted chosen buildings)\n",
    "\n",
    "8. writes results back to Supabase as GeoJSON in a building_suitability table\n",
    "\n",
    "Modularized so we can swap in better irradiance, panel efficiency, or LIDAR later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a5ff7a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "#pip install streamlit supabase osmnx geopandas rasterio shapely pyproj pydeck\n",
    "# all possibles so far, may need to add more as necessary\n",
    "import streamlit as st\n",
    "from supabase import create_client, Client\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import os\n",
    "import tempfile\n",
    "import rasterio\n",
    "from rasterio.mask import mask\n",
    "import osmnx as ox\n",
    "from shapely.geometry import Polygon, mapping\n",
    "import pydeck as pdk\n",
    "import json\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6bee9965",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Takes a while to run: 3m 13s for Tucson!\n",
    "def fetch_buildings_osm(place_name: str) -> tuple:\n",
    "    \"\"\"\n",
    "    Use OSMnx to fetch building footprints for the given place name.\n",
    "    Returns GeoDataFrame with area_m2 computed per building and total area.\n",
    "    \"\"\"\n",
    "    tags = {\"building\": True}\n",
    "    gdf = ox.features.features_from_place(place_name, tags=tags)\n",
    "    \n",
    "    # Filter to only Polygons and MultiPolygons\n",
    "    gdf = gdf[gdf.geometry.type.isin(['Polygon', 'MultiPolygon'])]\n",
    "    \n",
    "    # Residential/Commercial Classification\n",
    "    gdf[\"is_commercial\"] = gdf.apply(\n",
    "        lambda row: (\n",
    "            (pd.notna(row.get(\"building\")) and str(row.get(\"building\")).lower() in\n",
    "             [\"commercial\", \"retail\", \"industrial\", \"office\", \"warehouse\"])\n",
    "        ), axis=1\n",
    "    )\n",
    "\n",
    "    # Calculate the area (meters)\n",
    "    gdf_proj = ox.projection.project_gdf(gdf)\n",
    "    gdf['area_m2'] = gdf_proj.area\n",
    "\n",
    "    # Total area (sq m) covered by building footprints - this will go to City Specs\n",
    "    total_area = gdf['area_m2'].sum()\n",
    "\n",
    "    # put in some logic regarding the CNN identification of rooftops with PV, \n",
    "    # which will need to be discarded\n",
    "\n",
    "    return gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9f3a13e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tucson_gdf = fetch_buildings_osm(\"Tucson, Arizona\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8e4a5cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export columns to txt file\n",
    "tucson_gdf.columns.tolist()\n",
    "pd.Series(tucson_gdf.columns).to_csv(\"C:/Users/Owner/Documents/MADS/Capstone/Scripts/columns.txt\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c77bea03",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-03 14:46:00.298 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
     ]
    }
   ],
   "source": [
    "st.set_page_config(layout=\"wide\", page_title=\"Solar Suitability Planner\")\n",
    "\n",
    "# This is how I set up the secrets on my machine, not the same as Postgres!\n",
    "#url = st.secrets[\"SUPABASE_URL\"]\n",
    "#key = st.secrets[\"SUPABASE_KEY\"]\n",
    "#supabase: Client = create_client(url, key)\n",
    "\n",
    "# Default average daily insolation in kWh/m2/day (tweakable)\n",
    "DEFAULT_INSOLATION = {\n",
    "    \"Ann Arbor\": 4.0,   # ~kWh/m2/day \n",
    "    \"Tucson\": 6.0,\n",
    "}\n",
    "PANEL_EFFICIENCY = 0.18   # guessing, can replace from PV avgs\n",
    "PERFORMANCE_RATIO = 0.75  # guessing, can replace from PV avgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31ff504d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_demand_table(city: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Load city demand table from Supabase for selected city\n",
    "    Expected numeric column: MW and datetime column named 'date_time'.\n",
    "    \"\"\"\n",
    "    table_name = \"Ann_Arbor_demand\" if city == \"Ann Arbor\" else \"TEPC_demand\"\n",
    "    res = supabase.table(table_name).select(\"*\").execute()\n",
    "    data = res.data\n",
    "    df = pd.DataFrame(data)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aae53c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_city_annual_kwh(df: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Convert the 15-minute MW measurements into annual kWh.\n",
    "    Each MW measurement over a 15-min interval contributes: MW * 0.25 hours = MWh.\n",
    "    Sum of (MW) * 0.25 gives MWh per dataset period; multiply by 1000 to kWh.\n",
    "    Returns predicted value of next year's energy demand\n",
    "    \"\"\"\n",
    "    # For each year: sum(MW) * 0.25 hours = MWh -> convert to kWh\n",
    "    summary = (\n",
    "        df.groupby('Year')['MW']\n",
    "        .sum()\n",
    "        .reset_index(name='total_MW_sum')\n",
    "    )\n",
    "    summary['annual_kWh'] = summary['total_MW_sum'] * 0.25 * 1000\n",
    "\n",
    "    summary = summary.sort_values(\"Year\").reset_index(drop=True)\n",
    "    summary[\"growth_rate\"] = summary[\"annual_kWh\"].pct_change()\n",
    "\n",
    "    last_year = summary.iloc[-1][\"Year\"]\n",
    "    last_demand = summary.iloc[-1][\"annual_kWh\"]\n",
    "    last_growth = summary.iloc[-1][\"growth_rate\"]\n",
    "\n",
    "    predicted = last_demand * (1 + last_growth)\n",
    "\n",
    "    return print(predicted)   # remove print for production"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6578657c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#annual_demand_df = pd.read_csv(\"C:/Users/Owner/Documents/MADS/Capstone/Data/Demand data?TEPC_demand_complete.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "32f3ab00",
   "metadata": {},
   "outputs": [],
   "source": [
    "def polygon_orientation(polygon: Polygon):\n",
    "    \"\"\"\n",
    "    Estimate roof orientation (degrees clockwise from North) by minimum_rotated_rectangle method.\n",
    "    Returns degrees 0-360 where 0 = East? We'll return as degrees clockwise from North:\n",
    "    convert from arctan2(dx, dy) with adjustments.\n",
    "    \"\"\"\n",
    "    if polygon.is_empty:\n",
    "        return np.nan\n",
    "    mrr = polygon.minimum_rotated_rectangle\n",
    "    coords = list(mrr.exterior.coords)\n",
    "    max_len = 0\n",
    "    best_angle = None\n",
    "    # iterate edges\n",
    "    for i in range(len(coords)-1):\n",
    "        x1,y1 = coords[i]\n",
    "        x2,y2 = coords[i+1]\n",
    "        dx = x2 - x1\n",
    "        dy = y2 - y1\n",
    "        edge_len = np.hypot(dx, dy)\n",
    "        if edge_len > max_len:\n",
    "            max_len = edge_len\n",
    "            best_angle = np.degrees(np.arctan2(dy, dx))\n",
    "    if best_angle is None:\n",
    "        return np.nan\n",
    "    # best_angle is angle from +x axis (East) CCW. Convert to degrees clockwise from North:\n",
    "    # angle_from_north_clockwise = (90 - best_angle) mod 360\n",
    "    angle = (90 - best_angle) % 360\n",
    "    return angle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a6696286",
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_tilt_from_height_and_span(gdf: gpd.GeoDataFrame) -> gpd.GeoDataFrame:\n",
    "    \"\"\"\n",
    "    Estimate roof tilt in degrees using any available height / building:levels or fallback heuristics.\n",
    "\n",
    "    - If 'height' available (meters), use it\n",
    "    - Else if 'building:levels' available, multiply by 3.2\n",
    "    - Else fallback to small heights with default tilt for commercial vs residential\n",
    "    \"\"\"\n",
    "    # handle numeric heights\n",
    "    if \"height\" in gdf.columns:\n",
    "        heights = pd.to_numeric(gdf[\"height\"], errors=\"coerce\")\n",
    "    elif \"building:levels\" in gdf.columns:\n",
    "        heights = pd.to_numeric(gdf[\"building:levels\"], errors=\"coerce\") * 3.2\n",
    "    else:\n",
    "        heights = pd.Series(np.nan, index=gdf.index)\n",
    "\n",
    "    # Effective roof span (approx): use sqrt(area) or MRR longest edge-derived width\n",
    "    def approx_width(geom):\n",
    "        try:\n",
    "            mrr = geom.minimum_rotated_rectangle\n",
    "            # approximate width by dividing perimeter by 4 (rectangle assumption)\n",
    "            perim = mrr.length\n",
    "            width = perim / 4.0\n",
    "            return max(width, np.sqrt(geom.area))  # safe fallback\n",
    "        except Exception:\n",
    "            return np.sqrt(geom.area)\n",
    "\n",
    "    gdf[\"width_m\"] = gdf.geometry.to_crs(epsg=3857).apply(lambda geom: approx_width(geom))\n",
    "    # assign heights fallback\n",
    "    heights_filled = heights.fillna(5.0)  # 5m fallback\n",
    "    # tilt = arctan(height / (width/2)) [approx roof pitch]\n",
    "    gdf[\"tilt_deg\"] = np.degrees(np.arctan2(heights_filled, gdf[\"width_m\"]/2.0))\n",
    "    # clamp sensible range\n",
    "    gdf[\"tilt_deg\"] = gdf[\"tilt_deg\"].clip(3, 45)\n",
    "    return gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "75a20480",
   "metadata": {},
   "outputs": [],
   "source": [
    "# May be able to calculate using saved Azimuth values and MATH\n",
    "\n",
    "def orientation_match_score(roof_angle_deg: float, ideal_sun_azimuth_deg: float):\n",
    "    \"\"\"\n",
    "    Compute orientation match score 0-1 where 1 = perfect face to sun,\n",
    "    using smallest absolute difference on circle (0..180)\n",
    "    \"\"\"\n",
    "    diff = abs(roof_angle_deg - ideal_sun_azimuth_deg) % 360\n",
    "    if diff > 180:\n",
    "        diff = 360 - diff\n",
    "    # map 0->1, 180->0\n",
    "    return 1.0 - (diff / 180.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "46cee92f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "element   id    \n",
      "relation  129137    269.693881\n",
      "          131142    180.000000\n",
      "          131540     90.000000\n",
      "          132433    270.000000\n",
      "Name: orientation_deg, dtype: float64\n",
      "element   id    \n",
      "relation  129137     5.088872\n",
      "          131142    10.229916\n",
      "          131540    11.275210\n",
      "          132433     5.461403\n",
      "Name: tilt_deg, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "tucson_gdf[\"orientation_deg\"] = tucson_gdf.geometry.apply(lambda g: polygon_orientation(g))\n",
    "tucson_gdf = estimate_tilt_from_height_and_span(tucson_gdf)\n",
    "print(tucson_gdf['orientation_deg'].iloc[:4])\n",
    "print(tucson_gdf['tilt_deg'].iloc[:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f34061f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_building_annual_potential_kwh(gdf: gpd.GeoDataFrame, insolation_kwh_m2_day: float,\n",
    "                                           panel_efficiency=PANEL_EFFICIENCY, perf_ratio=PERFORMANCE_RATIO):\n",
    "    \"\"\"\n",
    "    Estimate the annual kWh each building can produce.\n",
    "    \"\"\"\n",
    "   # Set limit on useable area\n",
    "    COMMERCIAL_FRACTION = 0.50\n",
    "    RESIDENTIAL_FRACTION = 0.25 \n",
    "\n",
    "    # Compute usable area\n",
    "    gdf[\"usable_fraction\"] = gdf[\"is_commercial\"].apply(\n",
    "        lambda x: COMMERCIAL_FRACTION if x else RESIDENTIAL_FRACTION\n",
    "    )\n",
    "    gdf[\"usable_area_m2\"] = gdf[\"area_m2\"] * gdf[\"usable_fraction\"]\n",
    "\n",
    "    # Energy factor based on insolation + efficiency\n",
    "    daily = float(insolation_kwh_m2_day)\n",
    "    factor = daily * 365.0 * panel_efficiency * perf_ratio\n",
    "    gdf[\"annual_potential_kwh\"] = gdf[\"usable_area_m2\"] * factor\n",
    "\n",
    "    return gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "409d1faf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "element   id    \n",
      "relation  129137    848604.365481\n",
      "          131142    135763.718108\n",
      "          131540     91702.155404\n",
      "          132433    453590.012136\n",
      "Name: annual_potential_kwh, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "use_df = fetch_buildings_osm(\"Tucson, Arizona\")\n",
    "potential_df = estimate_building_annual_potential_kwh(gdf=use_df, insolation_kwh_m2_day=6.0)\n",
    "print(potential_df['annual_potential_kwh'].iloc[:4])\n",
    "\n",
    "# Example from SolarTO: \n",
    "# System size:14 kw, \n",
    "# Annual electricity generation:16,417 kwh, \n",
    "# Roof size suitable for solar: 3,230.88 m2 (10,600 sq ft)\n",
    "# This says \n",
    "# Annual elctricity is: 84,8604 kwh\n",
    "# Roof size: 2,870.3 m2 roof"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00ac737b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "element   id    \n",
      "relation  129137    2870.300577\n",
      "          131142     459.204188\n",
      "          131540     310.171336\n",
      "          132433    1534.212793\n",
      "Name: usable_area_m2, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(potential_df['usable_area_m2'].iloc[:4])\n",
    "# Results still need tweaking\n",
    "# How many panels per usable area?\n",
    "# Num hours of daylight - plug in sunrise/sunset\n",
    "# Can't add snow factor, no way to tie in without lat/long\n",
    "# Toronto: yield = 16,417 / 14 = 1,172 kWh/kW/year\n",
    "# will need azimuth for more accuracy\n",
    "# use estimated yield per location to identify overall loss factor (since we can't add all the realistic ones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "888ef3d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_buildings_to_meet_target(gdf: gpd.GeoDataFrame, required_kwh: float, commercial_pct: float):\n",
    "    \"\"\"\n",
    "    Greedy selection that alternates choosing commercial/residential in a ratio\n",
    "    that tries to match the requested commercial_pct while picking highest solar_score first.\n",
    "    Returns GeoDataFrame of selected buildings and remaining totals.\n",
    "    \"\"\"\n",
    "    # split pools\n",
    "    comm = gdf[gdf[\"is_commercial\"]==True].sort_values(\"solar_score\", ascending=False).copy()\n",
    "    resid = gdf[gdf[\"is_commercial\"]==False].sort_values(\"solar_score\", ascending=False).copy()\n",
    "\n",
    "    # iteratively pick from pools to reach required_kwh\n",
    "    sel_rows = []\n",
    "    ptr_comm = 0\n",
    "    ptr_resid = 0\n",
    "    total_selected_kwh = 0.0\n",
    "    selected_comm = 0\n",
    "    selected_total = 0\n",
    "\n",
    "    # Avoid division by zero: desired fraction [0..1]\n",
    "    desired_comm_frac = commercial_pct / 100.0\n",
    "\n",
    "    # Safety: if both pools empty, return empty\n",
    "    while total_selected_kwh < required_kwh and (ptr_comm < len(comm) or ptr_resid < len(resid)):\n",
    "        # choose which pool to pick from based on current fraction\n",
    "        current_frac = (selected_comm / selected_total) if selected_total > 0 else 0.0\n",
    "        pick_comm = False\n",
    "        # If we have not yet reached desired commercial fraction and comm pool not empty -> pick commercial\n",
    "        if current_frac < desired_comm_frac and ptr_comm < len(comm):\n",
    "            pick_comm = True\n",
    "        # else pick residential if available\n",
    "        elif ptr_resid < len(resid):\n",
    "            pick_comm = False\n",
    "        # else fallback to commercial if residential exhausted\n",
    "        elif ptr_comm < len(comm):\n",
    "            pick_comm = True\n",
    "        else:\n",
    "            break\n",
    "\n",
    "        if pick_comm:\n",
    "            row = comm.iloc[ptr_comm]\n",
    "            ptr_comm += 1\n",
    "        else:\n",
    "            row = resid.iloc[ptr_resid]\n",
    "            ptr_resid += 1\n",
    "\n",
    "        sel_rows.append(row)\n",
    "        total_selected_kwh += float(row[\"annual_potential_kwh\"])\n",
    "        selected_total += 1\n",
    "        if row[\"is_commercial\"]:\n",
    "            selected_comm += 1\n",
    "\n",
    "    selected_gdf = gpd.GeoDataFrame(sel_rows).reset_index(drop=True) if len(sel_rows) > 0 else gpd.GeoDataFrame(columns=gdf.columns)\n",
    "    # compute metrics\n",
    "    actual_comm_pct = (selected_comm / selected_total * 100.0) if selected_total > 0 else 0.0\n",
    "    return selected_gdf, total_selected_kwh, selected_total, actual_comm_pct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69a30e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_suitability_scores(gdf: gpd.GeoDataFrame, irradiance_factor: float, ideal_sun_azimuth: float):\n",
    "    \"\"\"\n",
    "    Compose final solar_score from orientation, tilt, shade, irradiance and area.\n",
    "    We compute intermediate scores in [0,1] and combine with weights.\n",
    "    \"\"\"\n",
    "    # orientation\n",
    "    gdf[\"orientation_deg\"] = gdf.geometry.apply(lambda geom: polygon_orientation(geom))\n",
    "    gdf[\"orientation_score\"] = gdf[\"orientation_deg\"].apply(lambda a: orientation_match_score(a, ideal_sun_azimuth))\n",
    "    # tilt: ideal ~25 deg (residential) -> score drops as further away\n",
    "    gdf[\"tilt_score\"] = 1.0 - (np.abs(gdf[\"tilt_deg\"] - 25.0) / 40.0)\n",
    "    gdf[\"tilt_score\"] = gdf[\"tilt_score\"].clip(0,1)\n",
    "    # shade already 0..1 where 1 is shaded; we want exposure_score = 1 - shade\n",
    "    gdf[\"exposure_score\"] = (1.0 - gdf[\"shade\"]).clip(0,1)\n",
    "    # irradiance_factor applied uniformly (0..1)\n",
    "    irr = float(np.clip(irradiance_factor, 0.0, 1.0))\n",
    "    # combine: weights can be tuned\n",
    "    gdf[\"solar_score\"] = (\n",
    "        0.35 * gdf[\"orientation_score\"] +\n",
    "        0.25 * gdf[\"tilt_score\"] +\n",
    "        0.25 * gdf[\"exposure_score\"] +\n",
    "        0.15 * irr\n",
    "    )\n",
    "    gdf[\"solar_score\"] = gdf[\"solar_score\"].clip(0,1)\n",
    "    return gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74418e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Results summary\n",
    "st.metric(\"Total area available for PV installation (sq m)\", f\"{Total_area:,.0f}\")\n",
    "st.metric(\"Annual kwh demand\", f\"{annual_kwh:,.0f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cbe77c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Buttons\n",
    "if st.sidebar.button(\"Run full model\"):\n",
    "    with st.spinner(\"Loading demand data from Supabase...\"):\n",
    "        df_demand = load_demand_table(city)\n",
    "    if df_demand.empty:\n",
    "        st.error(\"Loaded demand table is empty. Check Supabase table names and permissions.\")\n",
    "        st.stop()\n",
    "\n",
    "    with st.spinner(\"Computing annual energy need...\"):\n",
    "        annual_kwh = compute_city_annual_kwh(df_demand)\n",
    "\n",
    "    required_kwh = annual_kwh * (solar_pct / 100.0)\n",
    "\n",
    "    # Raster load (optional)\n",
    "    # We expect satellite files stored under 'satellite/{city_filename}.tif' in bucket \"satellite\"\n",
    "    tif_name = \"ann_arbor.tif\" if city == \"Ann Arbor\" else \"tucson.tif\"\n",
    "    try:\n",
    "        with st.spinner(\"Downloading GeoTIFF from Supabase...\"):\n",
    "            raster = download_geotiff_from_supabase(\"satellite\", tif_name)\n",
    "    except Exception as e:\n",
    "        st.warning(f\"Could not download GeoTIFF: {e}. Continuing without shade (shade=0).\")\n",
    "        raster = None\n",
    "\n",
    "    with st.spinner(\"Fetching building footprints from OSM (this may take a minute)...\"):\n",
    "        place_name = f\"{city}, USA\"\n",
    "        try:\n",
    "            buildings = fetch_buildings_osm(place_name)\n",
    "        except Exception as e:\n",
    "            st.error(f\"OSMnx fetch failed: {e}\")\n",
    "            st.stop()\n",
    "\n",
    "    # compute geometry-derived features\n",
    "    with st.spinner(\"Estimating roof geometry (orientation, tilt, area)...\"):\n",
    "        # orientation, tilt heuristics\n",
    "        buildings[\"orientation_deg\"] = buildings.geometry.apply(lambda g: polygon_orientation(g))\n",
    "        buildings = estimate_tilt_from_height_and_span(buildings)\n",
    "\n",
    "    # shade\n",
    "    if raster is not None:\n",
    "        st.info(\"Computing simple shade index from GeoTIFF per building (may take a while for many buildings)...\")\n",
    "        # apply shade (cautious about time; if many buildings, sample or parallelize)\n",
    "        shade_vals = []\n",
    "        for idx, row in stqdm := stqdm if \"stqdm\" in globals() else enumerate(buildings.itertuples()):  # safe fallback\n",
    "            # above line builds a variable stqdm only if available; fallback enumerate\n",
    "            break\n",
    "        # We'll not rely on stqdm; do plain loop with progress\n",
    "        progress = st.progress(0)\n",
    "        total = len(buildings)\n",
    "        shades = []\n",
    "        for i, (idx, row) in enumerate(buildings.iterrows()):\n",
    "            try:\n",
    "                s = shade_from_geotiff(raster, row.geometry)\n",
    "            except Exception:\n",
    "                s = 0.0\n",
    "            shades.append(s)\n",
    "            if total > 0:\n",
    "                progress.progress(int((i+1)/total * 100))\n",
    "        buildings[\"shade\"] = shades\n",
    "        progress.empty()\n",
    "    else:\n",
    "        buildings[\"shade\"] = 0.0\n",
    "\n",
    "    # irradiance factor (normalize to 0..1) using daylight/azimuth proxies from demand df\n",
    "    # We'll compute a simple irradiance_factor: map insolation value into 0..1 by dividing by 7 (approx max)\n",
    "    irr_factor = np.clip(insolation_override / 7.0, 0.0, 1.0)\n",
    "    # ideal sun azimuth: take mean of sunrise->sunset azimuths if available else 180 (south)\n",
    "    if {\"azimuth_sunrise\",\"azimuth_sunset\"}.issubset(df_demand.columns):\n",
    "        try:\n",
    "            mean_azimuth_range = ((df_demand[\"azimuth_sunset\"] + df_demand[\"azimuth_sunrise\"]) / 2.0).mean()\n",
    "            ideal_azimuth = float(mean_azimuth_range)\n",
    "        except Exception:\n",
    "            ideal_azimuth = 180.0\n",
    "    else:\n",
    "        ideal_azimuth = 180.0\n",
    "\n",
    "    with st.spinner(\"Computing solar suitability scores and annual potential...\"):\n",
    "        buildings = compute_suitability_scores(buildings, irr_factor, ideal_azimuth)\n",
    "        buildings = estimate_building_annual_potential_kwh(buildings, insolation_override)\n",
    "\n",
    "    # Selection algorithm\n",
    "    with st.spinner(\"Selecting buildings to meet target while respecting commercial mix...\"):\n",
    "        selected_gdf, tot_kwh_sel, n_selected, actual_comm_pct = select_buildings_to_meet_target(buildings, required_kwh, commercial_pct)\n",
    "\n",
    "    st.write(f\"Selected {n_selected} buildings producing ~**{tot_kwh_sel:,.0f} kWh/year** (target was {required_kwh:,.0f} kWh).\")\n",
    "    st.write(f\"Requested commercial%: **{commercial_pct}%** — actual selected commercial%: **{actual_comm_pct:.1f}%**\")\n",
    "\n",
    "    # Map visualization: PyDeck with two layers: all buildings choropleth, and selected highlighted\n",
    "    # GeoJSON for all buildings colored by solar_score\n",
    "    all_geojson = json.loads(buildings.to_json())\n",
    "    selected_geojson = json.loads(selected_gdf.to_json()) if not selected_gdf.empty else {\"type\":\"FeatureCollection\",\"features\":[]}\n",
    "\n",
    "    # prepare color function in PyDeck: we will store color arrays in properties\n",
    "    def score_to_color(score):\n",
    "        # green (good) to red (bad) mapping — returns [r,g,b,a]\n",
    "        g = int(np.clip(score,0,1) * 255)\n",
    "        r = int((1 - np.clip(score,0,1)) * 255)\n",
    "        return [r, g, 30, 140]\n",
    "\n",
    "    # add colors as properties to geojson features\n",
    "    for feat in all_geojson[\"features\"]:\n",
    "        score = feat[\"properties\"].get(\"solar_score\", 0.0)\n",
    "        feat[\"properties\"][\"color\"] = score_to_color(score)\n",
    "\n",
    "    for feat in selected_geojson.get(\"features\", []):\n",
    "        # highlight selected with a bright blue\n",
    "        feat[\"properties\"][\"color\"] = [30, 144, 255, 200]\n",
    "\n",
    "    # layers\n",
    "    all_layer = pdk.Layer(\n",
    "        \"GeoJsonLayer\",\n",
    "        all_geojson,\n",
    "        get_fill_color=\"properties.color\",\n",
    "        get_line_color=[80,80,80],\n",
    "        pickable=True,\n",
    "        stroked=True,\n",
    "        filled=True,\n",
    "        opacity=0.6,\n",
    "    )\n",
    "    sel_layer = pdk.Layer(\n",
    "        \"GeoJsonLayer\",\n",
    "        selected_geojson,\n",
    "        get_fill_color=\"properties.color\",\n",
    "        get_line_color=[0,0,0],\n",
    "        pickable=True,\n",
    "        stroked=True,\n",
    "        filled=True,\n",
    "        opacity=0.9,\n",
    "    )\n",
    "\n",
    "    # compute center\n",
    "    center = buildings.geometry.unary_union.centroid\n",
    "    initial_view = pdk.ViewState(latitude=center.y, longitude=center.x, zoom=13, pitch=40)\n",
    "\n",
    "    st.pydeck_chart(pdk.Deck(layers=[all_layer, sel_layer], initial_view_state=initial_view, map_style=\"mapbox://styles/mapbox/light-v9\"))\n",
    "\n",
    "    # Results summary\n",
    "    st.header(\"Results\")\n",
    "    st.metric(\"City annual energy (kWh)\", f\"{annual_kwh:,.0f}\")\n",
    "    st.metric(\"Solar target (kWh/year)\", f\"{required_kwh:,.0f}\")\n",
    "    st.metric(\"Selected buildings (count)\", f\"{n_selected}\")\n",
    "    st.metric(\"Selected potential (kWh/year)\", f\"{tot_kwh_sel:,.0f}\")\n",
    "    st.write(\"Distribution of solar_score among selected buildings:\")\n",
    "    if not selected_gdf.empty:\n",
    "        st.bar_chart(selected_gdf[\"solar_score\"].value_counts(bins=10).sort_index())\n",
    "\n",
    "    # Save geometry results to Supabase\n",
    "    if st.button(\"Save suitability results to Supabase\"):\n",
    "        try:\n",
    "            payload = {\n",
    "                \"city\": city,\n",
    "                \"geojson\": json.loads(buildings.to_json())\n",
    "            }\n",
    "            insert = supabase.table(\"building_suitability\").insert(payload).execute()\n",
    "            st.success(\"Saved building_suitability record to Supabase.\")\n",
    "        except Exception as e:\n",
    "            st.error(f\"Could not save to Supabase: {e}\")\n",
    "\n",
    "    st.success(\"Model run complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c30b7136",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save geometry results to Supabase"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01e50ba4",
   "metadata": {},
   "source": [
    "Notes:\n",
    "\n",
    "-might use LiDAR (DEM) for true solar path shading\n",
    "\n",
    "-currently using default irradiance values (Ann Arbor ~4, Tucson ~6 kWh/m²/day), but maybe can be replaced with city-specific measured irradiance (NREL) for better accuracy\n",
    "\n",
    "-add an endpoint to export selected parcels as GeoJSON/CSV\n",
    "\n",
    "-store results back in Supabase (then the app only reads results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
